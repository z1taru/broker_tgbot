# api/app/api/routes/ask.py
from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_session
from app.schemas.ask import AskRequest, AskResponse
from app.core.logging_config import get_logger

from app.ai.intent_router import IntentRouter
from app.ai.gpt_service import GPTService
from app.ai.embeddings_enhanced import EmbeddingService
from app.ai.search_enhanced import EnhancedSearchService
from app.ai.language_detector import LanguageDetector
from app.ai.decision import DecisionEngine

logger = get_logger(__name__)
router = APIRouter()

@router.post("/ask", response_model=AskResponse)
async def ask_question(
    request: AskRequest,
    session: AsyncSession = Depends(get_session)
):
    """
    CONVERSATIONAL RAG - Ð¶Ð¸Ð²Ð¾Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ð±Ð¾Ñ‚
    """
    try:
        # 1. Language detection
        language = request.language
        if language == "auto":
            detector = LanguageDetector()
            language = detector.detect(request.question)
        
        logger.info(f"ðŸ” Question: '{request.question}' | Lang: {language}")
        
        # 2. Intent Classification
        intent_router = IntentRouter()
        intent_result = intent_router.detect_intent(request.question, language)
        
        intent = intent_result["intent"]
        logger.info(f"ðŸŽ¯ Intent: {intent} (confidence: {intent_result['confidence']:.2f})")
        
        # 3. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð¾ Ð¸Ð½Ñ‚ÐµÐ½Ñ‚Ñƒ
        gpt_service = GPTService()
        
        # === GREETING ===
        if intent == "greeting":
            response_text = await gpt_service.generate_persona_response(
                user_question=request.question,
                intent="greeting",
                language=language
            )
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²
            if language == "kk":
                response_text += "\n\nðŸ’¡ ÐœÑ‹ÑÐ°Ð»Ñ‹:\nâ€¢ Ð¨Ð¾Ñ‚ Ò›Ð°Ð»Ð°Ð¹ Ð°ÑˆÐ°Ð¼Ñ‹Ð·?\nâ€¢ ÐžÐ±Ð»Ð¸Ð³Ð°Ñ†Ð¸Ñ Ò›Ð°Ð»Ð°Ð¹ Ð°Ð»Ð°Ð¼Ñ‹Ð·?\nâ€¢ Ð’Ð°Ð»ÑŽÑ‚Ð° Ð°Ð¹Ñ‹Ñ€Ð±Ð°ÑÑ‹"
            else:
                response_text += "\n\nðŸ’¡ ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€:\nâ€¢ ÐšÐ°Ðº Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚ÑŒ ÑÑ‡ÐµÑ‚?\nâ€¢ ÐšÐ°Ðº ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ Ð¾Ð±Ð»Ð¸Ð³Ð°Ñ†Ð¸ÑŽ?\nâ€¢ ÐžÐ±Ð¼ÐµÐ½ Ð²Ð°Ð»ÑŽÑ‚Ñ‹"
            
            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=response_text,
                confidence=1.0
            )
        
        # === GENERAL ===
        elif intent == "general":
            response_text = await gpt_service.generate_persona_response(
                user_question=request.question,
                intent="general",
                language=language
            )
            
            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=response_text,
                confidence=0.9
            )
        
        # === OFF_TOPIC ===
        elif intent == "off_topic":
            if language == "kk":
                response_text = "ÐšÐµÑˆÑ–Ñ€Ñ–Ò£Ñ–Ð·, Ð¼ÐµÐ½ Ñ‚ÐµÐº Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸ÑÐ»Ð°Ñ€ Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÐ¼Ñ–Ð½ ðŸ“Š\n\nÐ¡Ò±Ñ€Ð°Ò“Ñ‹Ò£Ñ‹Ð·:\nâ€¢ Ð¨Ð¾Ñ‚ Ð°ÑˆÑƒ\nâ€¢ ÐžÐ±Ð»Ð¸Ð³Ð°Ñ†Ð¸Ñ/Ð°ÐºÑ†Ð¸Ñ Ð°Ð»Ñƒ\nâ€¢ Ð’Ð°Ð»ÑŽÑ‚Ð° Ð°Ð¹Ñ‹Ñ€Ð±Ð°ÑÑ‹\n\nÐ‘Ð°ÑÒ›Ð° Ñ‚Ð°Ò›Ñ‹Ñ€Ñ‹Ð¿ Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÑƒÑ€Ð°Ñ‚Ð¾Ñ€ Ò›Ñ‹Ð·Ð¼ÐµÑ‚Ñ–Ð½Ðµ Ð¶Ð°Ð·Ñ‹Ò£Ñ‹Ð·"
            else:
                response_text = "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸ÑÐ¼ ðŸ“Š\n\nÐœÐ¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ:\nâ€¢ ÐžÑ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ ÑÑ‡ÐµÑ‚Ð¾Ð²\nâ€¢ ÐŸÐ¾ÐºÑƒÐ¿ÐºÐ° Ð¾Ð±Ð»Ð¸Ð³Ð°Ñ†Ð¸Ð¹/Ð°ÐºÑ†Ð¸Ð¹\nâ€¢ ÐžÐ±Ð¼ÐµÐ½ Ð²Ð°Ð»ÑŽÑ‚Ñ‹\n\nÐŸÐ¾ Ð´Ñ€ÑƒÐ³Ð¸Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼ Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÐºÑƒÑ€Ð°Ñ‚Ð¾Ñ€Ñƒ"
            
            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=response_text,
                confidence=1.0
            )
        
        # === FAQ / UNCLEAR ===
        else:  # faq or unclear
            # Vector search
            embedding_service = EmbeddingService()
            query_embedding = await embedding_service.create_embedding(request.question)
            
            search_service = EnhancedSearchService()
            faqs_with_scores = await search_service.hybrid_search(
                session=session,
                query_embedding=query_embedding,
                query_text=request.question,
                language=language,
                limit=10
            )
            
            if not faqs_with_scores:
                # NO MATCH - persona fallback
                response_text = await gpt_service.generate_persona_response(
                    user_question=request.question,
                    intent="no_match",
                    language=language
                )
                
                if language == "kk":
                    response_text += "\n\nðŸ“ž ÐšÑƒÑ€Ð°Ñ‚Ð¾Ñ€ Ò›Ñ‹Ð·Ð¼ÐµÑ‚Ñ–: 10:00-20:00"
                else:
                    response_text += "\n\nðŸ“ž Ð¡Ð»ÑƒÐ¶Ð±Ð° ÐºÑƒÑ€Ð°Ñ‚Ð¾Ñ€Ð°: 10:00-20:00"
                
                return AskResponse(
                    action="no_match",
                    question=request.question,
                    message=response_text,
                    confidence=0.0
                )
            
            best_score = faqs_with_scores[0][1]
            
            # HIGH confidence (â‰¥ 0.65) - ÐŸÐ Ð¯ÐœÐžÐ™ ÐžÐ¢Ð’Ð•Ð¢ Ð¡ Ð’Ð˜Ð”Ð•Ðž
            if best_score >= 0.65:
                faq = faqs_with_scores[0][0]
                
                return AskResponse(
                    action="direct_answer",
                    question=request.question,
                    answer_text=faq['answer_text'],
                    video_url=faq.get('video_url'),
                    faq_id=faq['id'],
                    confidence=best_score
                )
            
            # MEDIUM confidence (0.45-0.65) - GPT synthesizes answer BUT KEEP VIDEO!
            elif best_score >= 0.45:
                best_faq = faqs_with_scores[0][0]
                
                answer = await gpt_service.generate_answer_from_faqs(
                    user_question=request.question,
                    matched_faqs=faqs_with_scores[:3],
                    language=language
                )
                
                return AskResponse(
                    action="direct_answer",
                    question=request.question,
                    answer_text=answer,
                    video_url=best_faq.get('video_url'),
                    faq_id=best_faq['id'],
                    confidence=best_score,
                    suggestions=[faq['question'] for faq, _ in faqs_with_scores[:3]]
                )
            
            # LOW confidence (0.30-0.45) - Clarification
            elif best_score >= 0.30:
                clarification = await gpt_service.generate_clarification_question(
                    user_question=request.question,
                    similar_faqs=faqs_with_scores[:3],
                    language=language
                )
                
                return AskResponse(
                    action="clarify",
                    question=request.question,
                    message=clarification,
                    confidence=best_score,
                    suggestions=[faq['question'] for faq, _ in faqs_with_scores[:3]]
                )
            
            # VERY LOW (<0.30) - Persona fallback
            else:
                response_text = await gpt_service.generate_persona_response(
                    user_question=request.question,
                    intent="unclear",
                    language=language,
                    context={"similar_faqs": [faq for faq, _ in faqs_with_scores[:3]]}
                )
                
                return AskResponse(
                    action="no_match",
                    question=request.question,
                    message=response_text,
                    confidence=best_score
                )
    
    except Exception as e:
        logger.error(f"âŒ Error: {e}", exc_info=True)
        
        # ÐšÐ Ð˜Ð¢Ð˜Ð§ÐÐž: ÐÐ• Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¾ÑˆÐ¸Ð±ÐºÑƒ!
        if language == "kk":
            fallback = "ÒšÐ°Ð·Ñ–Ñ€ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°Ð»Ñ‹Ò› Ð°Ò›Ð°Ñƒ Ð±Ð°Ñ€ ðŸ”§\n\nÐšÑƒÑ€Ð°Ñ‚Ð¾Ñ€ Ò›Ñ‹Ð·Ð¼ÐµÑ‚Ñ–Ð½Ðµ Ð¶Ð°Ð·Ñ‹Ò£Ñ‹Ð·, Ð¾Ð»Ð°Ñ€ ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÐ´Ñ–!\nðŸ“ž 10:00-20:00"
        else:
            fallback = "Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð½ÐµÐ¿Ð¾Ð»Ð°Ð´ÐºÐ° ðŸ”§\n\nÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÐºÑƒÑ€Ð°Ñ‚Ð¾Ñ€Ñƒ, Ð¾Ð½ Ð¿Ð¾Ð¼Ð¾Ð¶ÐµÑ‚!\nðŸ“ž 10:00-20:00"
        
        return AskResponse(
            action="no_match",
            question=request.question,
            message=fallback,
            confidence=0.0
        )