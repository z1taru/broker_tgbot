# api/app/api/routes/ask.py
from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_session
from app.schemas.ask import AskRequest, AskResponse
from app.core.logging_config import get_logger

from app.ai.intent_router import IntentRouter
from app.ai.gpt_service import GPTService
from app.ai.embeddings_enhanced import EmbeddingService
from app.ai.search_enhanced import EnhancedSearchService
from app.ai.language_detector import LanguageDetector
from app.ai.decision import DecisionEngine

logger = get_logger(__name__)
router = APIRouter()

@router.post("/ask", response_model=AskResponse)
async def ask_question(
    request: AskRequest,
    session: AsyncSession = Depends(get_session)
):
    """
    CONVERSATIONAL RAG - –∂–∏–≤–æ–π –¥–∏–∞–ª–æ–≥–æ–≤—ã–π –±–æ—Ç
    """
    try:
        # 1. Language detection
        language = request.language
        if language == "auto":
            detector = LanguageDetector()
            language = detector.detect(request.question)
        
        logger.info(f"üîç Question: '{request.question}' | Lang: {language}")
        
        # 2. Intent Classification
        intent_router = IntentRouter()
        intent_result = intent_router.detect_intent(request.question, language)
        
        intent = intent_result["intent"]
        logger.info(f"üéØ Intent: {intent} (confidence: {intent_result['confidence']:.2f})")
        
        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –∏–Ω—Ç–µ–Ω—Ç—É
        gpt_service = GPTService()
        
        # === GREETING ===
        if intent == "greeting":
            response_text = await gpt_service.generate_persona_response(
                user_question=request.question,
                intent="greeting",
                language=language
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            if language == "kk":
                response_text += "\n\nüí° –ú—ã—Å–∞–ª—ã:\n‚Ä¢ –®–æ—Ç “õ–∞–ª–∞–π –∞—à–∞–º—ã–∑?\n‚Ä¢ –û–±–ª–∏–≥–∞—Ü–∏—è “õ–∞–ª–∞–π –∞–ª–∞–º—ã–∑?\n‚Ä¢ –í–∞–ª—é—Ç–∞ –∞–π—ã—Ä–±–∞—Å—ã"
            else:
                response_text += "\n\nüí° –ù–∞–ø—Ä–∏–º–µ—Ä:\n‚Ä¢ –ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å —Å—á–µ—Ç?\n‚Ä¢ –ö–∞–∫ –∫—É–ø–∏—Ç—å –æ–±–ª–∏–≥–∞—Ü–∏—é?\n‚Ä¢ –û–±–º–µ–Ω –≤–∞–ª—é—Ç—ã"
            
            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=response_text,
                confidence=1.0
            )
        
        # === GENERAL ===
        elif intent == "general":
            response_text = await gpt_service.generate_persona_response(
                user_question=request.question,
                intent="general",
                language=language
            )
            
            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=response_text,
                confidence=0.9
            )
        
        # === OFF_TOPIC ===
        elif intent == "off_topic":
            if language == "kk":
                response_text = "–ö–µ—à—ñ—Ä—ñ“£—ñ–∑, –º–µ–Ω —Ç–µ–∫ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–ª–∞—Ä –±–æ–π—ã–Ω—à–∞ –∫”©–º–µ–∫—Ç–µ—Å–µ–º—ñ–Ω üìä\n\n–°“±—Ä–∞“ì—ã“£—ã–∑:\n‚Ä¢ –®–æ—Ç –∞—à—É\n‚Ä¢ –û–±–ª–∏–≥–∞—Ü–∏—è/–∞–∫—Ü–∏—è –∞–ª—É\n‚Ä¢ –í–∞–ª—é—Ç–∞ –∞–π—ã—Ä–±–∞—Å—ã\n\n–ë–∞—Å“õ–∞ —Ç–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞ –∫—É—Ä–∞—Ç–æ—Ä “õ—ã–∑–º–µ—Ç—ñ–Ω–µ –∂–∞–∑—ã“£—ã–∑"
            else:
                response_text = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –ø–æ–º–æ–≥–∞—é —Ç–æ–ª—å–∫–æ –ø–æ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–º üìä\n\n–ú–æ–≥—É –ø–æ–º–æ—á—å —Å:\n‚Ä¢ –û—Ç–∫—Ä—ã—Ç–∏–µ —Å—á–µ—Ç–æ–≤\n‚Ä¢ –ü–æ–∫—É–ø–∫–∞ –æ–±–ª–∏–≥–∞—Ü–∏–π/–∞–∫—Ü–∏–π\n‚Ä¢ –û–±–º–µ–Ω –≤–∞–ª—é—Ç—ã\n\n–ü–æ –¥—Ä—É–≥–∏–º –≤–æ–ø—Ä–æ—Å–∞–º –ø–∏—à–∏—Ç–µ –∫—É—Ä–∞—Ç–æ—Ä—É"
            
            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=response_text,
                confidence=1.0
            )
        
        # === FAQ / UNCLEAR ===
        else:  # faq or unclear
            # Vector search
            embedding_service = EmbeddingService()
            query_embedding = await embedding_service.create_embedding(request.question)
            
            search_service = EnhancedSearchService()
            faqs_with_scores = await search_service.hybrid_search(
                session=session,
                query_embedding=query_embedding,
                query_text=request.question,
                language=language,
                limit=10
            )
            
            if not faqs_with_scores:
                # NO MATCH - persona fallback
                response_text = await gpt_service.generate_persona_response(
                    user_question=request.question,
                    intent="no_match",
                    language=language
                )
                
                if language == "kk":
                    response_text += "\n\nüìû –ö—É—Ä–∞—Ç–æ—Ä “õ—ã–∑–º–µ—Ç—ñ: 10:00-20:00"
                else:
                    response_text += "\n\nüìû –°–ª—É–∂–±–∞ –∫—É—Ä–∞—Ç–æ—Ä–∞: 10:00-20:00"
                
                return AskResponse(
                    action="no_match",
                    question=request.question,
                    message=response_text,
                    confidence=0.0
                )
            
            best_score = faqs_with_scores[0][1]
            best_faq = faqs_with_scores[0][0]
            
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–Ω–∏–∂–µ–Ω—ã –ø–æ—Ä–æ–≥–∏ confidence –¥–ª—è –ª—É—á—à–µ–≥–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
            
            # HIGH confidence (‚â• 0.40) - –ü–†–Ø–ú–û–ô –û–¢–í–ï–¢ –° –í–ò–î–ï–û
            if best_score >= 0.40:
                logger.info(f"‚úÖ HIGH confidence: {best_score:.3f} - returning direct answer with video")
                
                return AskResponse(
                    action="direct_answer",
                    question=request.question,
                    answer_text=best_faq['answer_text'],
                    video_url=best_faq.get('video_url'),
                    faq_id=best_faq['id'],
                    confidence=best_score
                )
            
            # MEDIUM confidence (0.20-0.40) - GPT synthesizes BUT KEEP VIDEO!
            elif best_score >= 0.20:
                logger.info(f"ü§î MEDIUM confidence: {best_score:.3f} - GPT synthesis with video")
                
                answer = await gpt_service.generate_answer_from_faqs(
                    user_question=request.question,
                    matched_faqs=faqs_with_scores[:3],
                    language=language
                )
                
                return AskResponse(
                    action="direct_answer",
                    question=request.question,
                    answer_text=answer,
                    video_url=best_faq.get('video_url'),  # ‚úÖ –í–ê–ñ–ù–û: –û—Å—Ç–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ!
                    faq_id=best_faq['id'],
                    confidence=best_score,
                    suggestions=[faq['question'] for faq, _ in faqs_with_scores[:3]]
                )
            
            # LOW confidence (0.10-0.20) - Clarification
            elif best_score >= 0.10:
                logger.info(f"üìã LOW confidence: {best_score:.3f} - asking for clarification")
                
                clarification = await gpt_service.generate_clarification_question(
                    user_question=request.question,
                    similar_faqs=faqs_with_scores[:3],
                    language=language
                )
                
                return AskResponse(
                    action="clarify",
                    question=request.question,
                    message=clarification,
                    confidence=best_score,
                    suggestions=[faq['question'] for faq, _ in faqs_with_scores[:3]]
                )
            
            # VERY LOW (<0.10) - Persona fallback BUT STILL SHOW BEST VIDEO IF EXISTS
            else:
                logger.info(f"‚ùå VERY LOW confidence: {best_score:.3f} - fallback with best match")
                
                response_text = await gpt_service.generate_persona_response(
                    user_question=request.question,
                    intent="unclear",
                    language=language,
                    context={"similar_faqs": [faq for faq, _ in faqs_with_scores[:3]]}
                )
                
                # ‚úÖ –ù–û–í–û–ï: –î–∞–∂–µ –ø—Ä–∏ no_match –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ª—É—á—à–µ–µ –≤–∏–¥–µ–æ, –µ—Å–ª–∏ –µ—Å—Ç—å
                return AskResponse(
                    action="no_match",
                    question=request.question,
                    message=response_text,
                    video_url=best_faq.get('video_url') if best_score > 0.05 else None,
                    faq_id=best_faq['id'] if best_score > 0.05 else None,
                    confidence=best_score
                )
    
    except Exception as e:
        logger.error(f"‚ùå Error: {e}", exc_info=True)
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É!
        if language == "kk":
            fallback = "“ö–∞–∑—ñ—Ä —Ç–µ—Ö–Ω–∏–∫–∞–ª—ã“õ –∞“õ–∞—É –±–∞—Ä üîß\n\n–ö—É—Ä–∞—Ç–æ—Ä “õ—ã–∑–º–µ—Ç—ñ–Ω–µ –∂–∞–∑—ã“£—ã–∑, –æ–ª–∞—Ä –∫”©–º–µ–∫—Ç–µ—Å–µ–¥—ñ!\nüìû 10:00-20:00"
        else:
            fallback = "–°–µ–π—á–∞—Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –Ω–µ–ø–æ–ª–∞–¥–∫–∞ üîß\n\n–ù–∞–ø–∏—à–∏—Ç–µ –∫—É—Ä–∞—Ç–æ—Ä—É, –æ–Ω –ø–æ–º–æ–∂–µ—Ç!\nüìû 10:00-20:00"
        
        return AskResponse(
            action="no_match",
            question=request.question,
            message=fallback,
            confidence=0.0
        )