# api/app/api/routes/ask.py
from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_session
from app.schemas.ask import AskRequest, AskResponse
from app.core.logging_config import get_logger

from app.ai.gpt_service import GPTService
from app.ai.embeddings_enhanced import EmbeddingService
from app.ai.search_enhanced import EnhancedSearchService
from app.ai.language_detector import LanguageDetector
from app.ai.intent_router import IntentRouter

logger = get_logger(__name__)
router = APIRouter()

GREETING_WORDS = {
    '–ø—Ä–∏–≤–µ—Ç', '—Å”ô–ª–µ–º', '—Å–∞–ª–µ–º', 'hello', 'hi',
    '–¥–æ–±—Ä—ã–π', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '—Å”ô–ª–µ–º–µ—Ç—Å—ñ–∑', '“õ–∞–π—ã—Ä–ª—ã'
}

VAGUE_WORDS = {
    '–¥–∏–≤–∏–¥–µ–Ω–¥—ã', '–∫–∞—Ä—Ç–∞', '—Å—á–µ—Ç', '—Å—á—ë—Ç', '–∞–∫—Ü–∏–∏', '–¥–µ–Ω—å–≥–∏',
    '–ø–æ–º–æ—â—å', '–ø–æ–º–æ–≥–∏', '–≤–æ–ø—Ä–æ—Å', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', '–∫–∞–∫',
    '–¥–∏–≤–∏–¥–µ–Ω–¥—Ç–µ—Ä', '–∫–∞—Ä—Ç–æ—á–∫–∞', '—à–æ—Ç', '–∞–∫—Ü–∏—è–ª–∞—Ä', '–∞“õ—à–∞', '–∫”©–º–µ–∫'
}

# –Ø–≤–Ω–æ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ ‚Äî —Å—Ä–∞–∑—É off_topic –±–µ–∑ GPT
EXPLICIT_OFF_TOPIC = {
    # 18+
    '—Å–µ–∫—Å', '–ø–æ—Ä–Ω–æ', '—ç—Ä–æ—Ç–∏–∫–∞', 'xxx', '18+', '–∏–Ω—Ç–∏–º',
    # –î–µ—Ç—Å–∫–æ–µ
    '–º—É–ª—å—Ç—Ñ–∏–ª—å–º', '–¥–µ—Ç—Å–∫–æ–µ', '–±–∞–ª–∞–ª–∞—Ä', '–±–∞–ª–∞', '—Ä–µ–±—ë–Ω–æ–∫', '–¥–µ—Ç–∏',
    '–∏–≥—Ä—É—à–∫–∞', '—Å–∫–∞–∑–∫–∞', '–º—É–ª—å—Ç–∏–∫',
    # –ï–¥–∞/–±—ã—Ç
    '—Ä–µ—Ü–µ–ø—Ç', '–≥–æ—Ç–æ–≤–∏—Ç—å', '–µ–¥–∞', '—Ä–µ—Å—Ç–æ—Ä–∞–Ω',
    # –ü–æ–≥–æ–¥–∞
    '–ø–æ–≥–æ–¥–∞', '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞', '–¥–æ–∂–¥—å', '—Å–Ω–µ–≥',
    # –°–ø–æ—Ä—Ç
    '—Ñ—É—Ç–±–æ–ª', '–±–∞—Å–∫–µ—Ç–±–æ–ª', '—Å–ø–æ—Ä—Ç', '–º–∞—Ç—á',
    # –ü–æ–ª–∏—Ç–∏–∫–∞
    '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç', '–≤—ã–±–æ—Ä—ã', '–ø–∞—Ä—Ç–∏—è', '–≤–æ–π–Ω–∞',
    # –ú–µ–¥–∏—Ü–∏–Ω–∞
    '–ª–µ—á–µ–Ω–∏–µ', '–±–æ–ª–µ–∑–Ω—å', '–≤—Ä–∞—á', '—Ç–∞–±–ª–µ—Ç–∫–∏',
}


def classify_intent_fast(text: str) -> str:
    lower = text.lower().strip()

    # –Ø–≤–Ω—ã–π off-topic ‚Äî –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –æ—Ç–∫–∞–∑
    if any(w in lower for w in EXPLICIT_OFF_TOPIC):
        return 'off_topic'

    if any(w in lower for w in GREETING_WORDS) and len(lower) < 40:
        return 'greeting'

    return 'faq'


def is_vague_query(text: str) -> bool:
    """–°—Ü–µ–Ω–∞—Ä–∏–π 2: –∑–∞–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ –æ–±—â–∏–π"""
    lower = text.lower().strip()
    words = lower.split()
    if len(words) <= 2 and any(w in lower for w in VAGUE_WORDS):
        return True
    return False


def build_answer_text(faq: dict) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç —Å disclaimer"""
    answer = faq['answer_text']
    footer = faq.get('description_footer')
    if footer and footer.strip():
        answer = f"{answer}\n\n<i>{footer}</i>"
    return answer


@router.post("/ask", response_model=AskResponse)
async def ask_question(
    request: AskRequest,
    session: AsyncSession = Depends(get_session)
):
    language = "ru"

    try:
        # 1. Language detection
        language = request.language
        if language == "auto":
            detector = LanguageDetector()
            language = detector.detect(request.question)

        logger.info(f"üîç Question: '{request.question}' | Lang: {language}")

        # 2. Fast intent (–≤–∫–ª—é—á–∞–µ—Ç —è–≤–Ω—ã–π off-topic)
        intent = classify_intent_fast(request.question)
        logger.info(f"üéØ Fast intent: {intent}")

        gpt_service = GPTService()

        # === OFF_TOPIC ‚Äî –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –æ—Ç–∫–∞–∑ –±–µ–∑ GPT ===
        if intent == 'off_topic':
            logger.info("üö´ Off-topic detected, returning strict refusal")
            return AskResponse(
                action="no_match",
                question=request.question,
                message=gpt_service.get_off_topic_response(language),
                confidence=0.0
            )

        # === GREETING ===
        if intent == "greeting":
            response_text = await gpt_service.generate_persona_response(
                user_question=request.question,
                intent="greeting",
                language=language
            )
            if language == "kk":
                response_text += "\n\nüí° –ú—ã—Å–∞–ª—ã:\n‚Ä¢ –®–æ—Ç “õ–∞–ª–∞–π –∞—à–∞–º—ã–∑?\n‚Ä¢ –û–±–ª–∏–≥–∞—Ü–∏—è “õ–∞–ª–∞–π –∞–ª–∞–º—ã–∑?\n‚Ä¢ –í–∞–ª—é—Ç–∞ –∞–π—ã—Ä–±–∞—Å—ã"
            else:
                response_text += "\n\nüí° –ù–∞–ø—Ä–∏–º–µ—Ä:\n‚Ä¢ –ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å —Å—á–µ—Ç?\n‚Ä¢ –ö–∞–∫ –∫—É–ø–∏—Ç—å –æ–±–ª–∏–≥–∞—Ü–∏—é?\n‚Ä¢ –û–±–º–µ–Ω –≤–∞–ª—é—Ç—ã"

            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=response_text,
                confidence=1.0
            )

        # === –°–¶–ï–ù–ê–†–ò–ô 2: —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å ===
        if is_vague_query(request.question):
            logger.info("üîé Vague query detected, requesting clarification")

            embedding_service = EmbeddingService()
            query_embedding = await embedding_service.create_embedding(request.question)

            search_service = EnhancedSearchService()
            faqs_with_scores = await search_service.hybrid_search(
                session=session,
                query_embedding=query_embedding,
                query_text=request.question,
                language=language,
                limit=4
            )

            clarification = await gpt_service.generate_clarification_question(
                user_question=request.question,
                similar_faqs=faqs_with_scores,
                language=language
            )

            return AskResponse(
                action="clarify",
                question=request.question,
                message=clarification,
                confidence=0.5,
                suggestions=[faq['question'] for faq, _ in faqs_with_scores[:4]]
            )

        # === FAQ ‚Äî –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ ===
        embedding_service = EmbeddingService()
        query_embedding = await embedding_service.create_embedding(request.question)

        search_service = EnhancedSearchService()
        faqs_with_scores = await search_service.hybrid_search(
            session=session,
            query_embedding=query_embedding,
            query_text=request.question,
            language=language,
            limit=10
        )

        # === –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è GPT-–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ off_topic –µ—Å–ª–∏ fast check –Ω–µ –ø–æ–π–º–∞–ª ===
        # –î–µ–ª–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —Å–ª–∞–±—ã–µ (score < 0.30)
        if not faqs_with_scores or faqs_with_scores[0][1] < 0.30:
            intent_router = IntentRouter()
            gpt_intent = intent_router.detect_intent(request.question, language)
            logger.info(f"ü§ñ GPT intent check: {gpt_intent}")

            if gpt_intent.get("intent") == "off_topic":
                logger.info("üö´ GPT confirmed off-topic")
                return AskResponse(
                    action="no_match",
                    question=request.question,
                    message=gpt_service.get_off_topic_response(language),
                    confidence=0.0
                )

        # === –°–¶–ï–ù–ê–†–ò–ô 3: –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω ===
        if not faqs_with_scores:
            logger.info("‚ùå No results found")
            response_text = await gpt_service.generate_no_match_response(
                user_question=request.question,
                language=language
            )
            return AskResponse(
                action="no_match",
                question=request.question,
                message=response_text,
                confidence=0.0
            )

        best_score = faqs_with_scores[0][1]
        best_faq = faqs_with_scores[0][0]

        logger.info(f"üìä Best score: {best_score:.3f} | FAQ: {best_faq['question'][:50]}")

        # === –°–¶–ï–ù–ê–†–ò–ô 4: —É–≤–µ—Ä–µ–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ===
        if best_score >= 0.40:
            logger.info(f"‚úÖ HIGH confidence: {best_score:.3f}")
            return AskResponse(
                action="direct_answer",
                question=request.question,
                answer_text=build_answer_text(best_faq),
                video_url=best_faq.get('video_url'),
                faq_id=best_faq['id'],
                confidence=best_score
            )

        # === –°–¶–ï–ù–ê–†–ò–ô 1: –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–ª–∏–∑–∫–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π ‚Äî —É—Ç–æ—á–Ω—è–µ–º ===
        elif best_score >= 0.20:
            close_matches = [
                (faq, score) for faq, score in faqs_with_scores[:5]
                if score >= best_score * 0.80
            ]

            if len(close_matches) >= 2:
                logger.info(f"ü§î Multiple matches: {len(close_matches)} options")
                clarification = await gpt_service.generate_clarification_question(
                    user_question=request.question,
                    similar_faqs=close_matches,
                    language=language
                )
                return AskResponse(
                    action="clarify",
                    question=request.question,
                    message=clarification,
                    confidence=best_score,
                    suggestions=[faq['question'] for faq, _ in close_matches[:4]]
                )
            else:
                logger.info(f"ü§î Single MEDIUM match: {best_score:.3f}")
                answer = await gpt_service.generate_answer_from_faqs(
                    user_question=request.question,
                    matched_faqs=faqs_with_scores[:3],
                    language=language
                )
                footer = best_faq.get('description_footer')
                if footer and footer.strip():
                    answer = f"{answer}\n\n<i>{footer}</i>"

                return AskResponse(
                    action="direct_answer",
                    question=request.question,
                    answer_text=answer,
                    video_url=best_faq.get('video_url'),
                    faq_id=best_faq['id'],
                    confidence=best_score,
                    suggestions=[faq['question'] for faq, _ in faqs_with_scores[:3]]
                )

        # LOW confidence (0.10-0.20)
        elif best_score >= 0.10:
            logger.info(f"üìã LOW confidence: {best_score:.3f}")
            clarification = await gpt_service.generate_clarification_question(
                user_question=request.question,
                similar_faqs=faqs_with_scores[:3],
                language=language
            )
            return AskResponse(
                action="clarify",
                question=request.question,
                message=clarification,
                confidence=best_score,
                suggestions=[faq['question'] for faq, _ in faqs_with_scores[:3]]
            )

        # VERY LOW (< 0.10)
        else:
            logger.info(f"‚ùå VERY LOW confidence: {best_score:.3f}")
            response_text = await gpt_service.generate_no_match_response(
                user_question=request.question,
                language=language
            )
            return AskResponse(
                action="no_match",
                question=request.question,
                message=response_text,
                confidence=best_score
            )

    except Exception as e:
        logger.error(f"‚ùå Error: {e}", exc_info=True)

        if language == "kk":
            fallback = "“ö–∞–∑—ñ—Ä —Ç–µ—Ö–Ω–∏–∫–∞–ª—ã“õ –∞“õ–∞—É –±–∞—Ä üîß\n\n–ö—É—Ä–∞—Ç–æ—Ä “õ—ã–∑–º–µ—Ç—ñ–Ω–µ –∂–∞–∑—ã“£—ã–∑!\nüìû 10:00-20:00"
        else:
            fallback = "–°–µ–π—á–∞—Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –Ω–µ–ø–æ–ª–∞–¥–∫–∞ üîß\n\n–ù–∞–ø–∏—à–∏—Ç–µ –∫—É—Ä–∞—Ç–æ—Ä—É, –æ–Ω –ø–æ–º–æ–∂–µ—Ç!\nüìû 10:00-20:00"

        return AskResponse(
            action="no_match",
            question=request.question,
            message=fallback,
            confidence=0.0
        )